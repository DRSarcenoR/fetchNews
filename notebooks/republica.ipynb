{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "# scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "\n",
    "\n",
    "from CHN.general import Scrapping\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrap = Scrapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://republica.gt/'\n",
    "buscar = 'buscar/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = 'bernardo arevalo'\n",
    "name = '%20'.join(nombre.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    url + buscar + name, \n",
    "    proxies={'http': None, 'https': None}, \n",
    "    timeout=60,\n",
    "    verify=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/republica/base.html', 'w') as rep:\n",
    "    rep.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info_republica(soup) -> dict:\n",
    "    return {\n",
    "        \"title\": soup.select_one(\".nota__titulo-item a\").get_text(strip=True),\n",
    "        \"url\": soup.select_one(\".nota__titulo-item a\")[\"href\"],\n",
    "        \"category\": soup.select_one(\".nota__volanta--text\").get_text(strip=True),\n",
    "        \"time\": soup.select_one(\".nota__fecha\").get_text(strip=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulos = soup.find_all('article', class_='nota nota--linea nota')\n",
    "resultado = [extraer_info_republica(articulo) for articulo in articulos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginas = soup.find_all('a', class_='number')\n",
    "\n",
    "numeros = [int(element.text.strip()) for element in paginas if element.text.strip().isdigit()]\n",
    "\n",
    "max_page = max(numeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterando por las páginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio...\n",
      "Solicitando info pag 1\n",
      "Estado: 200\n",
      "Solicitando info pag 2\n",
      "Estado: 200\n",
      "Solicitando info pag 3\n",
      "Estado: 200\n",
      "Solicitando info pag 4\n",
      "Estado: 200\n",
      "Solicitando info pag 5\n",
      "Estado: 200\n",
      "Solicitando info pag 6\n",
      "Estado: 200\n",
      "Solicitando info pag 7\n",
      "Estado: 200\n",
      "Solicitando info pag 8\n",
      "Estado: 200\n",
      "Solicitando info pag 9\n",
      "Estado: 200\n",
      "Solicitando info pag 10\n",
      "Estado: 200\n",
      "Solicitando info pag 11\n",
      "Estado: 200\n",
      "Solicitando info pag 12\n",
      "Estado: 200\n",
      "Solicitando info pag 13\n",
      "Estado: 200\n",
      "Solicitando info pag 14\n",
      "Estado: 200\n",
      "Solicitando info pag 15\n",
      "Estado: 200\n",
      "Solicitando info pag 16\n",
      "Estado: 200\n",
      "Solicitando info pag 17\n",
      "Estado: 200\n",
      "Solicitando info pag 18\n",
      "Estado: 200\n",
      "Solicitando info pag 19\n",
      "Estado: 200\n",
      "Solicitando info pag 20\n",
      "Estado: 200\n",
      "Solicitando info pag 21\n",
      "Estado: 200\n",
      "Solicitando info pag 22\n",
      "Estado: 200\n",
      "Solicitando info pag 23\n",
      "Estado: 200\n",
      "Solicitando info pag 24\n",
      "Estado: 200\n",
      "Solicitando info pag 25\n",
      "Estado: 200\n",
      "Solicitando info pag 26\n",
      "Estado: 200\n",
      "Solicitando info pag 27\n",
      "Estado: 200\n",
      "Solicitando info pag 28\n",
      "Estado: 200\n",
      "Solicitando info pag 29\n",
      "Estado: 200\n",
      "Solicitando info pag 30\n",
      "Estado: 200\n",
      "Solicitando info pag 31\n",
      "Estado: 200\n",
      "Solicitando info pag 32\n",
      "Estado: 200\n",
      "Solicitando info pag 33\n",
      "Estado: 200\n",
      "Solicitando info pag 34\n",
      "Estado: 200\n",
      "Solicitando info pag 35\n",
      "Estado: 200\n",
      "Solicitando info pag 36\n",
      "Estado: 200\n",
      "Solicitando info pag 37\n",
      "Estado: 200\n",
      "Solicitando info pag 38\n",
      "Estado: 200\n",
      "Solicitando info pag 39\n",
      "Estado: 200\n",
      "Solicitando info pag 40\n",
      "Estado: 200\n",
      "Solicitando info pag 41\n",
      "Estado: 200\n",
      "Solicitando info pag 42\n",
      "Estado: 200\n",
      "Solicitando info pag 43\n",
      "Estado: 200\n",
      "Solicitando info pag 44\n",
      "Estado: 200\n",
      "Solicitando info pag 45\n",
      "Estado: 200\n",
      "Solicitando info pag 46\n",
      "Estado: 200\n",
      "Solicitando info pag 47\n",
      "Estado: 200\n",
      "Solicitando info pag 48\n",
      "Estado: 200\n",
      "Solicitando info pag 49\n",
      "Estado: 200\n",
      "Solicitando info pag 50\n",
      "Estado: 200\n",
      "Solicitando info pag 51\n",
      "Estado: 200\n",
      "Solicitando info pag 52\n",
      "Estado: 200\n",
      "Solicitando info pag 53\n",
      "Estado: 200\n",
      "Solicitando info pag 54\n",
      "Estado: 200\n",
      "Solicitando info pag 55\n",
      "Estado: 200\n",
      "Solicitando info pag 56\n",
      "Estado: 200\n",
      "Solicitando info pag 57\n",
      "Estado: 200\n",
      "Solicitando info pag 58\n",
      "Estado: 200\n",
      "Solicitando info pag 59\n",
      "Estado: 200\n",
      "Solicitando info pag 60\n",
      "Estado: 200\n",
      "Solicitando info pag 61\n",
      "Estado: 200\n",
      "Solicitando info pag 62\n",
      "Estado: 200\n",
      "Solicitando info pag 63\n",
      "Estado: 200\n",
      "Solicitando info pag 64\n",
      "Estado: 200\n",
      "Solicitando info pag 65\n",
      "Estado: 200\n",
      "Solicitando info pag 66\n",
      "Estado: 200\n"
     ]
    }
   ],
   "source": [
    "full = []\n",
    "print('Inicio...')\n",
    "for i in range(1, max_page + 1):\n",
    "    # agregamos el número de página\n",
    "    page = f'/{i}/'\n",
    "    print(f'Solicitando info pag {i}')\n",
    "    \n",
    "    try:\n",
    "        # solicitamos la información de la pag\n",
    "        response = requests.get(\n",
    "            url + buscar + name + page, \n",
    "            proxies={'http': None, 'https': None}, \n",
    "            timeout=60,\n",
    "            verify=False)\n",
    "        print(f'Estado: {response.status_code}')\n",
    "\n",
    "        # si se recibio respuesta correcta, parseamos\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # extraemos la información de los articulos\n",
    "            articulos = soup.find_all(\"article\", class_='nota nota--linea nota')\n",
    "            resultado = [extraer_info_republica(articulo) for articulo in articulos]\n",
    "\n",
    "            # juntamos la data en formato json\n",
    "            data = {\"page\": i, \"articulos\": resultado}\n",
    "            full.append(data)\n",
    "    except RequestException as e:\n",
    "        print(f'Error al procesar pagina {i}: {e}')\n",
    "        continue\n",
    "\n",
    "\n",
    "info = json.dumps({'epInvestiga': full}, indent=4, ensure_ascii=False)\n",
    "with open(f\"../data/republica/resultados_1_{nombre}.json\", 'w', encoding='utf-8') as f:\n",
    "    f.write(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### para un articulo extaer el texto en especifico y analizarlo o darselo a chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_art = 'https://republica.gt/politica/diputados-de-la-une-afin-a-sandra-torres-piden-interpelar-a-cuatro-ministros-de-arevalo--202512814220'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = scrap.genRequest(url_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "with open('../data/republica/articulo.html', 'w') as rep:\n",
    "    rep.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_articulo(soup) -> dict:\n",
    "    # Extraer el título\n",
    "    titulo = soup.find('h1')  # Supongamos que el título está en un <h1>\n",
    "    titulo_text = titulo.get_text(strip=True) if titulo else 'No disponible'\n",
    "\n",
    "    # Extraer el autor\n",
    "    autor = soup.find('a', class_='autor-link')\n",
    "    autor_text = autor.get_text(strip=True) if autor else 'No disponible'\n",
    "\n",
    "    # Extraer la fecha\n",
    "    fecha = soup.find('div', class_='entry--mobile__fecha')\n",
    "    fecha_text = fecha.get_text(strip=True) if fecha else 'No disponible'\n",
    "\n",
    "    # Extraer el contenido del artículo\n",
    "    contenido = soup.find('div', class_='articulo__cuerpo')\n",
    "    contenido_text = contenido.get_text(strip=True) if contenido else 'No disponible'\n",
    "\n",
    "    # Crear un diccionario con la información\n",
    "    articulo_info = {\n",
    "        'titulo': titulo_text,\n",
    "        'autor': autor_text,\n",
    "        'fecha': fecha_text,\n",
    "        'contenido': contenido_text\n",
    "    }\n",
    "    return articulo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/republica/articulo1_prueba.json', 'w', encoding='utf-8') as art:\n",
    "    json.dump(info_articulo(soup), art, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "presentacion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
